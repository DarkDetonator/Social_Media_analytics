{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025d20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada37a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22e6fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['status_id', 'status_message', 'link_name', 'status_type',\n",
      "       'status_link', 'status_published', 'num_reactions', 'num_comments',\n",
      "       'num_shares', 'num_likes', 'num_loves', 'num_wows', 'num_hahas',\n",
      "       'num_sads', 'num_angrys'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Facebook dataset\n",
    "facebook_data = pd.read_csv(r\"C:\\Users\\ACER\\Downloads\\trump.csv\")\n",
    "\n",
    "# Print column names\n",
    "print(facebook_data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2348c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive    2323\n",
      "Neutral     1253\n",
      "Negative     584\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the Facebook dataset\n",
    "facebook_data = pd.read_csv(r\"C:\\Users\\ACER\\Downloads\\trump.csv\")\n",
    "\n",
    "# Perform sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(str(text))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply sentiment analysis to each post\n",
    "facebook_data['sentiment'] = facebook_data['status_message'].apply(get_sentiment)\n",
    "\n",
    "sentiment_counts = facebook_data['sentiment'].value_counts()\n",
    "\n",
    "# View the results\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35bac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words:\n",
      "great: 1149\n",
      "america: 1028\n",
      "trump: 961\n",
      "thank: 793\n",
      "make: 776\n",
      "hillary: 736\n",
      "clinton: 693\n",
      "people: 547\n",
      "new: 532\n",
      "country: 442\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords data (only need to do this once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the Facebook dataset\n",
    "facebook_data = pd.read_csv(r\"C:\\Users\\ACER\\Downloads\\trump.csv\")\n",
    "\n",
    "# Tokenize text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = []\n",
    "for post in facebook_data['status_message']:\n",
    "    tokens = word_tokenize(str(post))\n",
    "    words = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    word_tokens.extend(words)\n",
    "\n",
    "# Count word occurrences\n",
    "word_counts = Counter(word_tokens)\n",
    "\n",
    "# Print the most common words\n",
    "print(\"Most common words:\")\n",
    "for word, count in word_counts.most_common(10):  # Change 10 to the number of top words you want to see\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0001a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
